{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "\n",
    "1. Take a moment to confirm the configuration details. You can run it with default settings to get a 3 node cluster with 21GB of RAM\n",
    "2. Run the cell bellow to configure the spark cluster\n",
    "\n",
    "### Note:\n",
    "You can change the driver and executor max memory and number of nodes by changing the following\n",
    "\n",
    "``“driverMemory”:”21G”\n",
    "“executorMemory”:”21G\n",
    "“numExecutors”:3\n",
    "``\n",
    "\n",
    "For more info, check the documentation [here][1]\n",
    "\n",
    "[1]: http://h2o-release.s3.amazonaws.com/h2o/latest_azure_doc.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.ext.h2o.announce.rest.url\": \"http://@@IPADDRESS@@:5000/flows\",\n",
    "        \"spark.jars\":\"/H2O-Sparkling-Water-files/sparkling-water-assembly-all.jar\",\n",
    "        \"spark.submit.pyFiles\":\"/H2O-Sparkling-Water-files/pySparkling.zip\",\n",
    "        \"spark.locality.wait\":\"3000\",\n",
    "        \"spark.scheduler.minRegisteredResourcesRatio\":\"1\",\n",
    "        \"spark.task.maxFailures\":\"1\",\n",
    "        \"spark.yarn.am.extraJavaOption\":\"-XX:MaxPermSize=384m\",\n",
    "        \"spark.yarn.max.executor.failures\":\"1\",\n",
    "        \"maximizeResourceAllocation\": \"true\"\n",
    "    },\n",
    "    \"driverMemory\":\"21G\",\n",
    "    \"executorMemory\":\"21G\",\n",
    "    \"numExecutors\":3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pysparkling, h2o\n",
    "import os\n",
    "os.environ[\"PYTHON_EGG_CACHE\"] = \"~/\"\n",
    "sc.addPyFile(\"wasb:///H2O-Sparkling-Water-files/pySparkling.zip\") # For Azure DataLake replace wasb with adl\n",
    "\n",
    "h2o_context = pysparkling.H2OContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O FLOW\n",
    "\n",
    "H2O Flow is a  interactive web-based computational user interface where you can combine code execution, text, mathematics, plots and rich media into a single document, much like Jupyter Notebooks.\n",
    "\n",
    "With H2O Flow, you can capture, rerun, annotate, present, and share your workflow. H2O Flow allows you to use H2O interactively to import files, build models, and iteratively improve them. Based on your models, you can make predictions and add rich text to create vignettes of your work - all within Flow’s browser-based environment. \n",
    "\n",
    "An H2O Flow instance is always running when H2O is started, even from R or Python. Users can use Flow in conjunction with their coding environment to evaluate model performance & scoring history easily during an training run. They can also monitor cluster & CPU usage and perform data explorations using the built-in visualizations.\n",
    "\n",
    "### Note\n",
    "Please wait for the previous cell to finish executing (and start H2O) before opening the H2O Flow page\n",
    "\n",
    "###### H2O FLOW can be found at @@FLOWURL@@\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
